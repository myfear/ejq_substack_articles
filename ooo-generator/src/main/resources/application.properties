# LangChain4j -> Ollama
quarkus.langchain4j.ollama.chat-model.model-name=gpt-oss:20b
quarkus.langchain4j.ollama.chat-model.temperature=0.2

# Local models can be slow on laptops
quarkus.langchain4j.timeout=90s

# Logging during development
quarkus.langchain4j.log-requests=true
quarkus.langchain4j.log-responses=true